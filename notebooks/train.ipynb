{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "english_words_demo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FzQ_YsQvCJuM",
        "colab_type": "text"
      },
      "source": [
        "# English Words in TensorFlow\n",
        "\n",
        "### Generating English-like Words\n",
        "I want to create a game where I present the user with a string of characters and the user has to guess whether the word is a genuine English word or something that was made up. For this to work, I need to find a way to generate realistic word-like character strings. To achieve this I'm going to try a ML technology call Generative Adversarial Networks (GAN):\n",
        "  \n",
        "  ![image.png](data:image/png;base64,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)\n",
        "\n",
        "*(image adapted fromborrowed from [this website](https://miro.medium.com/))*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OHiAuimkQ7_",
        "colab_type": "text"
      },
      "source": [
        "### Jupyter Notebooks, Colab & TensorFlow\n",
        "This demonstration uses Colab which is an online service offered by Google. It uses a slightly modified version of Jupyter Notebooks. \n",
        "\n",
        "Alternative Jupyter Notebook ML environments include [Kaggle](https://kaggle.com/) and [Azure Notebooks](https://notebooks.azure.com)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-6SbZYQHNZB",
        "colab_type": "text"
      },
      "source": [
        "### STEP 1: Importing Libraries\n",
        "By default, Colabs uses TensorFlow 1. To use TensorFlow 2 we need to execute a bit of special code before importing the library. To execute code in a Colabs environment we just write it in a cell and execute it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBcxYJcvO_kn",
        "colab_type": "code",
        "outputId": "307caf3e-905e-49f4-e4d9-c711b6111ace",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import dill\n",
        "import gzip\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt \n",
        "import pandas as pd\n",
        "import string\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "\n",
        "np.set_printoptions(edgeitems=30, linewidth=10000, \n",
        "    formatter=dict(float=lambda x: \"%.3g\" % x))"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47LEHP_3DXqE",
        "colab_type": "text"
      },
      "source": [
        "### STEP 2: Loading Dataset & Encode/Decode Functions from Google Cloud Storage\n",
        "\n",
        "As this is quite a short session, I have preprepared a dataset with over a million words, as well as functions that encode and decode arbitrary lists of words into the same format. I serialised these items using a package called `dill` and put them in a Google Storage Bucket. I'll load them back in here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntOxoi-HD6cF",
        "colab_type": "code",
        "outputId": "3a625183-31eb-4e01-a33d-39eb3e5d3103",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "def download_file(local_basename, remote_filename):\n",
        "    baseurl = 'https://storage.googleapis.com/files.mxklabs.co.uk/machine-learning/english-words/'\n",
        "    return tf.keras.utils.get_file(local_basename, baseurl + remote_filename)\n",
        "\n",
        "def load_python_object_from_filename(filename):\n",
        "    with gzip.open(filename, 'rb') as file:\n",
        "        return dill.load(file)\n",
        "\n",
        "encode = load_python_object_from_filename(download_file('encode', 'to_recur_onehot20.dill.gz'))\n",
        "decode = load_python_object_from_filename(download_file('decode', 'from_recur_onehot20.dill.gz'))\n",
        "dataset = load_python_object_from_filename(download_file('dataset', 'dataset_recur_onehot20.dill.gz'))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/files.mxklabs.co.uk/machine-learning/english-words/to_recur_onehot20.dill.gz\n",
            "\r8192/626 [========================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/files.mxklabs.co.uk/machine-learning/english-words/from_recur_onehot20.dill.gz\n",
            "8192/505 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/files.mxklabs.co.uk/machine-learning/english-words/dataset_recur_onehot20.dill.gz\n",
            "44720128/44717521 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6iRuj67IKNo",
        "colab_type": "text"
      },
      "source": [
        "### STEP 3: Show Me The Data!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XVWTYy1T5mP",
        "colab_type": "code",
        "outputId": "dd7037b2-e6ca-4fe7-c605-3ae192fcd7ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "print(f'x.shape={dataset.train.x.shape}')\n",
        "print(f'y.shape={dataset.train.y.shape}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x.shape=(521863, 21, 27)\n",
            "y.shape=(521863, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eM7zw3DeGM3M",
        "colab_type": "code",
        "outputId": "72d27804-4f93-4b45-e1ca-208232513b5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "source": [
        "x_subset = dataset.train.x[29:30,:,:]\n",
        "y_subset = dataset.train.y[29:30,:]\n",
        "\n",
        "print(\"   \" + \" \".join(string.ascii_uppercase))\n",
        "print(x_subset)\n",
        "print(f'Word: {decode(x_subset)} -> {y_subset[0]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   A B C D E F G H I J K L M N O P Q R S T U V W X Y Z\n",
            "[[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "  [0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0]]]\n",
            "Word: ['bulls'] -> [1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "og2a7ie_jp8F",
        "colab_type": "code",
        "outputId": "eaeb8501-b098-4dd6-ab81-545cb04a2c5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        }
      },
      "source": [
        "x_subset = dataset.train.x[65:66,:,:]\n",
        "y_subset = dataset.train.y[65:66,:]\n",
        "\n",
        "print(\"   \" + \" \".join(string.ascii_uppercase))\n",
        "print(x_subset)\n",
        "print(f'Word: {decode(x_subset)} -> {y_subset[0]}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   A B C D E F G H I J K L M N O P Q R S T U V W X Y Z\n",
            "[[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0]\n",
            "  [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0]\n",
            "  [0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "  [0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
            "  [1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]]\n",
            "Word: ['xtoxrazyuwnwgna'] -> [0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXAo0MvUk11x",
        "colab_type": "text"
      },
      "source": [
        "### STEP 4: Keras / TensorFlow model\n",
        "Keras is a high-level API for machine learning. TensorFlow is one of the low-level computational frameworks that Keras supports. Definine a neural network is just a few lines of code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4DeFgKUbesk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_batched_data_subset(x, y, batch_size=500, prefetch=10):\n",
        "    result = tf.data.Dataset.from_tensor_slices((x, y))\n",
        "    return result.batch(batch_size).prefetch(prefetch) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etlXad2qk7LD",
        "colab_type": "code",
        "outputId": "45342601-29cf-46ad-9adc-b4b3f31e7c92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "source": [
        "# Define a model.\n",
        "discriminator = tf.keras.models.Sequential(name='discriminator')\n",
        "discriminator.add(tf.keras.layers.LSTM(name='dlstm', units=500, use_bias=True, activation='tanh', input_shape=dataset.train.x[0].shape))\n",
        "discriminator.add(tf.keras.layers.Dense(name='dhidden1', units=100, use_bias=True, activation='tanh'))\n",
        "discriminator.add(tf.keras.layers.Dense(name='dhidden2', units=10, use_bias=True, activation='tanh'))\n",
        "discriminator.add(tf.keras.layers.Dense(name='doutput', units=1, use_bias=True, activation='linear'))\n",
        "\n",
        "# Compile it.\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "discriminator.compile(optimizer=opt, loss='binary_crossentropy', metrics=['binary_accuracy'])\n",
        "\n",
        "# Train it.\n",
        "discriminator.fit(to_batched_data_subset(dataset.train.x, dataset.train.y, batch_size=500), \n",
        "          validation_data=to_batched_data_subset(dataset.val.x, dataset.val.y), \n",
        "          validation_steps=20, verbose=1, epochs=120,\n",
        "          callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 1044 steps, validate for 20 steps\n",
            "Epoch 1/120\n",
            "1044/1044 [==============================] - 28s 27ms/step - loss: 0.3049 - binary_accuracy: 0.8945 - val_loss: 0.2023 - val_binary_accuracy: 0.9312\n",
            "Epoch 2/120\n",
            "1044/1044 [==============================] - 20s 19ms/step - loss: 0.2096 - binary_accuracy: 0.9331 - val_loss: 0.1960 - val_binary_accuracy: 0.9327\n",
            "Epoch 3/120\n",
            "1044/1044 [==============================] - 20s 19ms/step - loss: 0.2240 - binary_accuracy: 0.9274 - val_loss: 0.1781 - val_binary_accuracy: 0.9399\n",
            "Epoch 4/120\n",
            "1044/1044 [==============================] - 20s 19ms/step - loss: 0.2061 - binary_accuracy: 0.9311 - val_loss: 0.1712 - val_binary_accuracy: 0.9406\n",
            "Epoch 5/120\n",
            "1044/1044 [==============================] - 20s 19ms/step - loss: 0.2162 - binary_accuracy: 0.9293 - val_loss: 0.1704 - val_binary_accuracy: 0.9377\n",
            "Epoch 6/120\n",
            "1044/1044 [==============================] - 20s 19ms/step - loss: 0.2561 - binary_accuracy: 0.9032 - val_loss: 0.2119 - val_binary_accuracy: 0.9213\n",
            "Epoch 7/120\n",
            "1044/1044 [==============================] - 20s 19ms/step - loss: 0.1994 - binary_accuracy: 0.9274 - val_loss: 0.1709 - val_binary_accuracy: 0.9366\n",
            "Epoch 8/120\n",
            "1044/1044 [==============================] - 20s 19ms/step - loss: 0.1822 - binary_accuracy: 0.9366 - val_loss: 0.1573 - val_binary_accuracy: 0.9435\n",
            "Epoch 9/120\n",
            "1044/1044 [==============================] - 20s 19ms/step - loss: 0.1866 - binary_accuracy: 0.9357 - val_loss: 0.1575 - val_binary_accuracy: 0.9453\n",
            "Epoch 10/120\n",
            "1044/1044 [==============================] - 20s 19ms/step - loss: 0.2082 - binary_accuracy: 0.9226 - val_loss: 0.1620 - val_binary_accuracy: 0.9414\n",
            "Epoch 11/120\n",
            "1044/1044 [==============================] - 20s 19ms/step - loss: 0.1743 - binary_accuracy: 0.9384 - val_loss: 0.1683 - val_binary_accuracy: 0.9378\n",
            "Epoch 12/120\n",
            "1044/1044 [==============================] - 20s 19ms/step - loss: 0.1824 - binary_accuracy: 0.9333 - val_loss: 0.1515 - val_binary_accuracy: 0.9440\n",
            "Epoch 13/120\n",
            "1044/1044 [==============================] - 20s 19ms/step - loss: 0.1696 - binary_accuracy: 0.9396 - val_loss: 0.2621 - val_binary_accuracy: 0.9303\n",
            "Epoch 14/120\n",
            "1044/1044 [==============================] - 20s 19ms/step - loss: 0.1656 - binary_accuracy: 0.9425 - val_loss: 0.1440 - val_binary_accuracy: 0.9473\n",
            "Epoch 15/120\n",
            "1044/1044 [==============================] - 20s 19ms/step - loss: 0.1562 - binary_accuracy: 0.9458 - val_loss: 0.1389 - val_binary_accuracy: 0.9501\n",
            "Epoch 16/120\n",
            "1044/1044 [==============================] - 20s 19ms/step - loss: 0.1494 - binary_accuracy: 0.9485 - val_loss: 0.1310 - val_binary_accuracy: 0.9535\n",
            "Epoch 17/120\n",
            "1044/1044 [==============================] - 20s 19ms/step - loss: 0.1517 - binary_accuracy: 0.9480 - val_loss: 0.1356 - val_binary_accuracy: 0.9523\n",
            "Epoch 18/120\n",
            "1044/1044 [==============================] - 20s 19ms/step - loss: 0.1527 - binary_accuracy: 0.9493 - val_loss: 0.1234 - val_binary_accuracy: 0.9562\n",
            "Epoch 19/120\n",
            "1044/1044 [==============================] - 20s 19ms/step - loss: 0.1339 - binary_accuracy: 0.9534 - val_loss: 0.1134 - val_binary_accuracy: 0.9611\n",
            "Epoch 20/120\n",
            "1044/1044 [==============================] - 20s 19ms/step - loss: 0.1400 - binary_accuracy: 0.9533 - val_loss: 0.1124 - val_binary_accuracy: 0.9616\n",
            "Epoch 21/120\n",
            "1044/1044 [==============================] - 20s 19ms/step - loss: 0.1201 - binary_accuracy: 0.9600 - val_loss: 0.1040 - val_binary_accuracy: 0.9660\n",
            "Epoch 22/120\n",
            "1044/1044 [==============================] - 20s 19ms/step - loss: 0.1197 - binary_accuracy: 0.9607 - val_loss: 0.1022 - val_binary_accuracy: 0.9660\n",
            "Epoch 23/120\n",
            "1044/1044 [==============================] - 20s 19ms/step - loss: 0.1147 - binary_accuracy: 0.9621 - val_loss: 0.0930 - val_binary_accuracy: 0.9678\n",
            "Epoch 24/120\n",
            "1044/1044 [==============================] - 20s 19ms/step - loss: 0.1162 - binary_accuracy: 0.9628 - val_loss: 0.0906 - val_binary_accuracy: 0.9707\n",
            "Epoch 25/120\n",
            "1044/1044 [==============================] - 20s 19ms/step - loss: 0.1201 - binary_accuracy: 0.9619 - val_loss: 0.1061 - val_binary_accuracy: 0.9628\n",
            "Epoch 26/120\n",
            "  31/1044 [..............................] - ETA: 39s - loss: 0.1082 - binary_accuracy: 0.9630"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lLFK6WgxrwX7",
        "colab_type": "text"
      },
      "source": [
        "### STEP 4 (shortcut): Here's One I Cooked Earlier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44dcAvYbdcZ5",
        "colab_type": "code",
        "outputId": "49679ea0-a34e-47a2-caf1-a9a1c1de4083",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "discriminator = tf.keras.models.load_model(download_file('model', 'model.h5'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/files.mxklabs.co.uk/machine-learning/english-words/model.h5\n",
            "13328384/13325864 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yp66gRzmrl14",
        "colab_type": "text"
      },
      "source": [
        "### STEP 5: Sanity Checking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwnWtNCOJpig",
        "colab_type": "text"
      },
      "source": [
        "Let's first confirm that our model's performance on the validation set is what we expect."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HQLskuwormVY",
        "colab_type": "code",
        "outputId": "27e23287-6ed7-4d54-f27c-6fbf32640722",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "pred_y   = (discriminator.predict(dataset.val.x) > 0.5)\n",
        "actual_y = (dataset.val.y == 1)\n",
        "\n",
        "accuracy = float (sum(pred_y == actual_y)) / dataset.val.y.size\n",
        "print(f'Accuracy: {accuracy*100:.03f}%')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy: 98.441%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0GTwk_rJvFX",
        "colab_type": "text"
      },
      "source": [
        "Let's see what kind of scores our model is actually giving the 'words' in the validation set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a2dqgXbtDKyP",
        "colab_type": "code",
        "outputId": "7b495449-09dd-4cd2-b6e7-765dfeb7789e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        }
      },
      "source": [
        "rand_pred_y = discriminator.predict(dataset.val.x[dataset.val.y[:,0] == 0]).ravel()\n",
        "word_pred_y = discriminator.predict(dataset.val.x[dataset.val.y[:,0] == 1]).ravel()\n",
        "\n",
        "fig, axs = plt.subplots(1, 2,figsize=(10,2))\n",
        "axs[0].hist(rand_pred_y, bins=100, range=(-1,2), color='red')\n",
        "axs[0].set_title('Random characters')\n",
        "axs[1].hist(word_pred_y, bins=100, range=(-1,2), color='blue')\n",
        "axs[1].set_title('Words')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 1.0, 'Words')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAmIAAACcCAYAAADcUcemAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAbf0lEQVR4nO3de7QV5Z3m8e8T4q3VCApB5CJeyEVN\nRw3jvbOMtIomLWZNYmt6Ati2JKNm6WrXJJieFS+J0yaTxLQrapZGRlAj2sa0tMEQVIwxE1BQvABx\nOKJGCDcFQROjQX/zR71Hi83enH3O2XtXnX2ez1p7UfW+b1W9uzi8/E7Ve1FEYGZmZmat976iK2Bm\nZmbWXzkQMzMzMyuIAzEzMzOzgjgQMzMzMyuIAzEzMzOzgjgQMzMzMyuIAzHrNknHS1pZcB0uk3Rr\nkXUwM2sGt2/9iwOxNiHpBUlvSHpd0hpJN0vareh6tTtJkyU9UnQ9zKx5JF0i6b6KtOU10s5sbe2s\nr3Mg1l7+LiJ2Aw4FDgMuKbg+fYKk9/fHa5tZ3R4GjpE0AEDSMGAH4LCKtANT2boo4/+H+zn/ALSh\niFgDzCELyACQ9GlJT0jaLOklSZfl8kZLCkmTJP1e0suS/iWXv0t6wrZR0lLgv+SvJ+mjkh6S9Kqk\nJZJOy+XdLOk6Sfelp3W/kbS3pB+k8/1O0mG1voukgyXNlbRB0lpJX89l7yhphqTX0nXH5o6bKum5\nlLdU0mdzeZNTPa6W9ApwmaQDJD0o6ZX0/W+TNDB3zEhJd0tan8r8UNJHgR8BR6fv9moqu5Ok76Z7\nuVbSjyTtkvKOl7RS0tckrQH+j6TBku5N92+DpF+7cTYrlcfIAq/ONvVvgHnAsxVpz0XEHyQdI+kx\nSZvSn8d0nii1lVdK+g3wJ2B/SftJ+lVqr+YCg3Pld5Z0a2p3Xk3nG9qC72wt4sa+DUkaAZwCdOSS\n/whMBAYCnwb+u6TTKw49DvgwMA74Rgo0AC4FDkifk4FJuWvtAPwn8Evgg8BXgNskfTh33jOA/0nW\nuLwJ/BZ4PO3fBXy/xvfYHbgf+AWwD9lvmw/kipwGzEzfaRbww1zec2QN4x7A5cCt6TfWTkcCK4Ch\nwJWAgH9N1/koMBK4LNVjAHAv8CIwGhgOzIyIZcCXgd9GxG4R0Rm4XQV8iKyBPjCV/0bu2nsDewL7\nAlOAi4GVwJBUn68DXnvMrCQi4i1gAfDJlPRJ4NfAIxVpD0vaE/g5cA2wF1n79nNJe+VO+UWyf/u7\nk7UrPwEWkbWJ3yTXxqbtPcjapL3I2pw3GvsNrVAR4U8bfIAXgNeB18j+E38AGLid8j8Ark7bo9Mx\nI3L5jwJnpu0VwPhc3hRgZdr+G2AN8L5c/u3AZWn7ZuDGXN5XgGW5/Y8Br9ao41nAEzXyLgPuz+0f\nBLyxne+7GJiQticDv+/ifp7eeW3gaGA98P4q5SYDj+T2RRb0HpBLOxp4Pm0fD7wF7JzLvwK4Bziw\n6J8jf/zxp/ontTk/S9tPAmOA8RVpk8iCrEcrjv0tMDltPwRckcsbBWwBds2l/QS4NW3/I/B/gb8u\n+h7405yPn4i1l9MjYney/+w/wtaPt4+UNC+9WttE9lvV4Irj1+S2/wR0dvbfB3gpl/dibnsf4KWI\neKcif3huf21u+40q+7UGFYwke7JVS2V9d+7scyVpoqTF6VH+q8AhbP19898HSUMlzZS0StJm4NZc\n+ZHAixGxZTt16TQE+CtgUe7av0jpndZHxJ9z+/+b7OnlLyWtkDS1juuYWWs9DByXnngNiYjlZAHS\nMSntkFRmH7ZuI2HbNjHf/uwDbIyIP1aU73QLWVeTmZL+IOk76U2EtQkHYm0oIn5F9iTqu7nkn5C9\nvhsZEXuQ9W1SnadcTRaMdBqV2/4DMLKiT9MoYFU3q13NS8D+3T1I0r7AjcAFwF6RvTJ8hq2/b+Wr\nv/+V0j4WER8A/luu/EvAKFXvWF95npfJgsuDI2Jg+uwR2SCKqsdExGsRcXFE7E/2uvWfJY2r9/ua\nWUv8luwV4bnAbwAiYjNZG3gu8IeIeD7t71txbGWbmG8DVgODJO1aUZ50jb9ExOURcRBwDPAZsm4m\n1iYciLWvHwAnSvp42t8d2BARf5Z0BPCFbpzrTuASSYNS/7Ov5PIWkD2N+qqkHSQdD/wdWd+t3roX\nGCbpotQBfndJR9Zx3K5kDd16AElnk/22uj27k73a3SRpOPA/cnmPkjWWV0naNXWePTblrQVGSNoR\nID0ZvBG4WtIH0/WHSzq51oUlfUbSgZIEbALeBt6pVd7MWi8i3gAWAv9M1j+s0yMprXO05GzgQ5K+\nIOn9kv6erOvEvTXO+2I67+WSdpR0HFkbCoCkT0n6WOqruhn4C24f2ooDsTYVEeuBGbzXSfw84ApJ\nr6W0O7txusvJHpU/T9Yp/5bcdd4iazROIXsadB0wMSJ+14Dv8BpwYjr/GmA58Kk6jlsKfI/sN9i1\nZP3QftPFYZcDh5MFQj8H7s6d7+1UhwOB35N1rP/7lP0gsARYI+nllPY1sleN89NrzvvJBkHUMiaV\neT3V+bqImNfV9zSzlvsV2aCk/NyBv05pDwNExCtkT60uBl4Bvgp8JiJeprYvkA0g2kA2OGpGLm9v\nskFNm4FlqQ63VJ7A+i5FeHCWmZmZWRH8RMzMzMysIA7EzMzMzAriQMzMzMysIA7EzMzMzAriQMzM\nzMysINUmqNyKpGlkQ3HXRcQhKW1P4A6ypXFeAM6IiI1pHqR/A04lm1tqckQ8no6ZRLbeIMC3ImJ6\nSv8E2eSju5DNv3Jh1DGUc/DgwTF69Oh6v6eZ9XGLFi16OSKGdF2y/Nx+mfU/tdqwLgMxsiDph2w9\nr8lU4IGIuCotxzKVbO6kU8jmRBpDNifK9cCRKXC7FBhLNtHmIkmzImJjKnMu2cSgs8nW7rqvq0qN\nHj2ahQsX1lF9M2sHkiqXjemz3H6Z9T+12rAuX01GxMNkk8zlTQCmp+3pZAskd6bPiMx8YKCkYcDJ\nwNyI2JCCr7nA+JT3gYiYn56Czcidy8zMzKyt9bSP2NCIWJ221wBD0/Zwtl7MdGVK2176yirpZmZm\nZm2v153105OslkzPL2mKpIWSFq5fv74VlzQzMzNrmp4GYmvTa0XSn+tS+ipgZK7ciJS2vfQRVdKr\niogbImJsRIwdMqQt+uw2h5R9zMzM6uT/OorR00BsFjApbU8C7smlT1TmKGBTeoU5BzhJ0iBJg4CT\ngDkpb7Oko9KIy4m5c5mZmZm1tXqmr7gdOB4YLGkl2ejHq4A7JZ0DvAickYrPJpu6ooNs+oqzASJi\ng6RvAo+lcldEROcAgPN4b/qK+6hjxKSZmZlZO+gyEIuIs2pkjatSNoDza5xnGjCtSvpC4JCu6mFm\nZmbWbjyzvpmZmVlBHIiZmZmZFcSBmJmZmVlBHIiZmZmZFaSetSatr/AEMGZmZn2Kn4iZWduTNEDS\nE5LuTfv7SVogqUPSHZJ2TOk7pf2OlD86d45LUvqzkk7OpY9PaR2Sprb6u5lZ3+ZAzMz6gwuBZbn9\nbwNXR8SBwEbgnJR+DrAxpV+dyiHpIOBM4GBgPHBdCu4GANcCpwAHAWelsmZmdXEgZmZtTdII4NPA\nj9O+gBOAu1KR6cDpaXtC2iflj0vlJwAzI+LNiHiebNLqI9KnIyJWRMRbwMxU1sysLg7EzKzd/QD4\nKvBO2t8LeDUitqT9lcDwtD0ceAkg5W9K5d9NrzimVrqZWV0ciJlZ25L0GWBdRCwqQV2mSFooaeH6\n9euLro6ZlYQDMTNrZ8cCp0l6gey14QnAvwEDJXWOGh8BrErbq4CRACl/D+CVfHrFMbXStxERN0TE\n2IgYO2TIkN5/MzNrCw7EzKxtRcQlETEiIkaTdbZ/MCL+AZgHfC4VmwTck7ZnpX1S/oNpDd1ZwJlp\nVOV+wBjgUeAxYEwahbljusasFnw1M2sTnkfMzPqjrwEzJX0LeAK4KaXfBNwiqQPYQBZYERFLJN0J\nLAW2AOdHxNsAki4A5gADgGkRsaSl38TM+jQHYmbWL0TEQ8BDaXsF2YjHyjJ/Bj5f4/grgSurpM8G\nZjewqmbWj/jVpJmZmVlBHIiZmZmZFcSBmJmZmVlBehyISfqwpMW5z2ZJF0m6TNKqXPqpuWO8VpuZ\nmZlZ0uPO+hHxLHAoZAvqks2d8zPgbLI13L6bL1+xVts+wP2SPpSyrwVOJJuV+jFJsyJiaU/rZmZm\nZtYXNGrU5DjguYh4MVuWrap312oDnk/DwztHLXWkUUxI6lyrzYGYmZmZtbVG9RE7E7g9t3+BpKck\nTZM0KKV5rbZWk7b9mJmZWWn0OhBLs0mfBvx7SroeOIDsteVq4Hu9vUbuWl6rzczMzNpGI56InQI8\nHhFrASJibUS8HRHvADfy3utHr9VmZmZmltOIQOwscq8lJQ3L5X0WeCZte602MzMzs5xeddaXtCvZ\naMcv5ZK/I+lQIIAXOvO8VpuZmZnZ1noViEXEH4G9KtK+uJ3yXqut0dwB38zMrM/yzPpmZmZmBXEg\nZmZmZlYQB2Jm1rYk7SzpUUlPSloi6fKUvp+kBWlZtTvSQCHSYKI7UvoCSaNz5/ISbWbWcA7EzKyd\nvQmcEBEfJ5vbcLyko4Bvky3FdiCwETgnlT8H2JjSr07lKpdoGw9cJ2lAWt7tWrJpfA4Czkplzczq\n4kDMzNpWZF5PuzukTwAnAHel9OnA6Wl7Qton5Y9Ttm7bu0u0RcTzQOcSbUeQlmiLiLeAziXazMzq\n4kDMzNpaenK1GFgHzAWeA16NiC2pSH5ZtXeXXEv5m8hGhvd6iTavDGJm1TgQ62+85qT1M2mlj0PJ\nVu04AvhIQfXwyiBmtg0HYmbWL0TEq8A84GhgoKTOeRTzy6q9u+Rayt8DeIUGLNFmZlaNAzEza1uS\nhkgamLZ3IVsJZBlZQPa5VGwScE/anpX2SfkPRkTgJdrMrEl6NbO+mVnJDQOmp9GN7wPujIh7JS0F\nZkr6FvAEcFMqfxNwi6QOYANZYOUl2sysaRyImVnbioingMOqpK8g6y9Wmf5n4PM1zuUl2sys4fxq\n0szMzKwgDsTMzMzMCuJAzMzMzKwgDsTMzMzMCuJAzMzMzKwgHjXZV3l2fDMzsz6vV0/EJL0g6WlJ\niyUtTGl7SporaXn6c1BKl6RrJHVIekrS4bnzTErll0uaVOt6ZmZmZu2kEa8mPxURh0bE2LQ/FXgg\nIsYAD6R9gFPIZqMeA0wBrocscAMuBY4km9fn0s7gzczMzKydNaOP2ARgetqeDpyeS58Rmflka70N\nA04G5kbEhojYCMwFxjehXmZmZmal0ttALIBfSlokaUpKGxoRq9P2GmBo2h4OvJQ7dmVKq5VuZmZm\n1tZ621n/uIhYJemDwFxJv8tnRkRIil5e410p2JsCMGrUqEad1szMzKwQvXoiFhGr0p/rgJ+R9fFa\nm145kv5cl4qvAkbmDh+R0mqlV7veDRExNiLGDhkypDdVNzMzMytcjwMxSbtK2r1zGzgJeAaYBXSO\nfJwE3JO2ZwET0+jJo4BN6RXmHOAkSYNSJ/2TUpo1k/Tex8zMzArRmydiQ4FHJD0JPAr8PCJ+AVwF\nnChpOfC3aR9gNrAC6ABuBM4DiIgNwDeBx9LnipRmZtYrkkZKmidpqaQlki5M6Q2bZkfSJ9I0Ph3p\nWP92Y2Z163EfsYhYAXy8SvorwLgq6QGcX+Nc04BpPa2LmVkNW4CLI+Lx9AR/kaS5wGSyaXaukjSV\nbJqdr7H1NDtHkk2zc2Rump2xZIOUFkmalUZ6Xw+cCywg+4VzPHBfC7+jmfVhXuLIzNpWRKyOiMfT\n9mvAMrJR2Q2ZZiflfSAi5qdfNmfkzmVm1iUvcdTX+K2HWY9IGg0cRvbkqlHT7AxP25XpZmZ18RMx\nM2t7knYDfgpcFBGb83npSVbDptnZTh2mSFooaeH69eubfTkz6yMciJlZW5O0A1kQdltE3J2SGzXN\nzqq0XZm+DU+/Y2bVOBAzs7aVRjDeBCyLiO/nshoyzU7K2yzpqHStiblzmZl1yX3EzKydHQt8EXha\n0uKU9nWyaXXulHQO8CJwRsqbDZxKNs3On4CzIZtmR1LnNDuw9TQ75wE3A7uQjZb0iEkzq5sDMTNr\nWxHxCFBrhEtDptmJiIXAIb2oppn1Y341aWZmZlYQB2JmZmZmBXEgZmZmZlYQB2JmZmZmBXEgZtls\n/Z6x38zMrOU8arKvcKBkZmbWdhyImZmZ9WP+Pb9YfjVpZmZmVhAHYmZmZmYFcSBmZmZmVhAHYmZm\nZmYF6XEgJmmkpHmSlkpaIunClH6ZpFWSFqfPqbljLpHUIelZSSfn0sentA5JU3v3lczMzMz6ht6M\nmtwCXBwRj0vaHVgkaW7KuzoivpsvLOkg4EzgYGAf4H5JH0rZ1wInAiuBxyTNioilvaibmZmZWen1\nOBCLiNXA6rT9mqRlwPDtHDIBmBkRbwLPS+oAjkh5HRGxAkDSzFTWgZjHFJuZmbW1hvQRkzQaOAxY\nkJIukPSUpGmSBqW04cBLucNWprRa6WZmvZbaoXWSnsml7SlprqTl6c9BKV2SrkndJJ6SdHjumEmp\n/HJJk3Lpn5D0dDrmGsm/QZlZ/XodiEnaDfgpcFFEbAauBw4ADiV7Yva93l4jd60pkhZKWrh+/fpG\nndY6eakja083A+Mr0qYCD0TEGOCBtA9wCjAmfaaQtWdI2hO4FDiS7En+pblfMq8Hzs0dV3ktM7Oa\nehWISdqBLAi7LSLuBoiItRHxdkS8A9zIe68fVwEjc4ePSGm10rcRETdExNiIGDtkyJDeVN3M+omI\neBjYUJE8AZietqcDp+fSZ0RmPjBQ0jDgZGBuRGyIiI3AXGB8yvtARMyPiABm5M5lZtal3oyaFHAT\nsCwivp9LH5Yr9lmg83XALOBMSTtJ2o/sN8dHgceAMZL2k7QjWYf+WT2tl5lZHYamfq4Aa4Chabu7\nXSiGp+3KdDOzuvRm1OSxwBeBpyUtTmlfB86SdCgQwAvAlwAiYomkO8k64W8Bzo+ItwEkXQDMAQYA\n0yJiSS/q1ff59aBZy0RESIpmX0fSFLLXnYwaNarZlzOzPqI3oyYfAapFDLO3c8yVwJVV0mdv7zgz\nswZbK2lYRKxOT/HXpfTtdaE4viL9oZQ+okr5bUTEDcANAGPHjm164GdmfYNn1jez/mgW0DnycRJw\nTy59Yho9eRSwKb3CnAOcJGlQ6qR/EjAn5W2WdFTqrjExdy4zsy715tWkmVnpSbqd7GnWYEkryUY/\nXgXcKekc4EXgjFR8NnAq0AH8CTgbICI2SPomWZ9WgCsionMAwHlkIzN3Ae5LHzOzujgQKxP3DTNr\nuIg4q0bWuCplAzi/xnmmAdOqpC8EDulNHc2s/3IgZtvKB4ThrixmZmbN4j5iZmZmZgXxE7Gi+XWk\nmZlZv+UnYmZmZmYF8ROxovhJmJmZWb/nQKzV+loA1llfd9o3MzNrOAdiZmZm/UxfeybQzhyItYJ/\n4s3MzKwKd9Y3MzMzK4ifiDVDOz4Bc18xMzOzhnMg1ijtGHxV44DMzMysYRyIdVdlINJfAjAzMzNr\nOAdi9agWbPX3AMzrUZqZ9Tn9/b+uMnIg1sk/nT3n15VmZmY9UppRk5LGS3pWUoekqS28sIOwRvG9\ntH6qsPbLzPq8UgRikgYA1wKnAAcBZ0k6qMkXddDQLJ331vfX+oFC2i+zbnKTXF6lCMSAI4COiFgR\nEW8BM4EJDb+KA4TWy9/zyk9lmWrHFG179TbLtKb9MquTm62+pSx9xIYDL+X2VwJHNuzs/iksp8q/\nl74yKGJ7dXI/uf6oue2X9VtlbP6s8coSiNVF0hRgStp9XdKzdR46GHi5ObXqtbLWzfXqvsFIZaxb\nue9Z/XXbt5kVaTa3Xy1V1npBeev2br1KGACW/p7VqWobVpZAbBUwMrc/IqVtJSJuAG7o7sklLYyI\nsT2vXvOUtW6uV/eVtW5lrReUu27d4ParZMpaLyhv3cpaLyhv3RpVr7L0EXsMGCNpP0k7AmcCswqu\nk5lZPdx+mVmPleKJWERskXQBMAcYAEyLiCUFV8vMrEtuv8ysN0oRiAFExGxgdpNO3+3XAS1U1rq5\nXt1X1rqVtV5Q7rrVze1X6ZS1XlDeupW1XlDeujWkXgqP8jIzMzMrRFn6iJmZmZn1O20ZiEn6vKQl\nkt6RVHNEQxHLkkjaU9JcScvTn4NqlHtb0uL0aVrH367ugaSdJN2R8hdIGt2sunSzXpMlrc/do39q\nUb2mSVon6Zka+ZJ0Tar3U5IOL0m9jpe0KXe/vtGieo2UNE/S0vRv8sIqZQq5Z2Xl9qtb9XH71b16\nlbL9qrNu7duGRUTbfYCPAh8GHgLG1igzAHgO2B/YEXgSOKgFdfsOMDVtTwW+XaPc6y2oS5f3ADgP\n+FHaPhO4oyT1mgz8sICfrU8ChwPP1Mg/FbgPEHAUsKAk9ToeuLeA+zUMODxt7w78vyp/l4Xcs7J+\n3H7VXRe3X92vWynbrzrr1rZtWFs+EYuIZRHR1WSJRS1LMgGYnranA6e34Jq11HMP8vW9CxgnNX26\nv9IuGRMRDwMbtlNkAjAjMvOBgZKGlaBehYiI1RHxeNp+DVhGNhN9XiH3rKzcftXN7Vc3lbX9qrNu\nhWhFG9aWgVidqi1LUnlzm2FoRKxO22uAoTXK7SxpoaT5kprV2NVzD94tExFbgE3AXk2qT3fqBfBf\n02PguySNrJJfhKJ+rupxtKQnJd0n6eBWXzy9FjoMWFCRVeZ7VlZuv9x+NUPZ/y22ZRtWmukrukvS\n/cDeVbL+JSLuaXV98rZXt/xORISkWsNW942IVZL2Bx6U9HREPNfouvZh/wncHhFvSvoS2W+9JxRc\npzJ7nOxn6nVJpwL/AYxp1cUl7Qb8FLgoIja36rpl5far33P71X1t24b12UAsIv62l6eoa1mSnthe\n3SStlTQsIlanR5frapxjVfpzhaSHyKLwRjdk9dyDzjIrJb0f2AN4pcH16Ha9IiJfhx+T9V0pg6b9\nXPVGvuGIiNmSrpM0OCKavn6bpB3IGrDbIuLuKkVKec+aye1XQ7j9arzS/lts5zasP7+aLGpZklnA\npLQ9Cdjmt19JgyTtlLYHA8cCS5tQl3ruQb6+nwMejNQ7sYm6rFfF+/fTyN7bl8EsYGIaRXMUsCn3\nKqcwkvbu7Bsj6Qiyf/vN/g+JdM2bgGUR8f0axUp5z0rO7Zfbr2Yo7b/Ftm7DejKKoOwf4LNk72jf\nBNYCc1L6PsDsXLlTyUZAPEf2SqAVddsLeABYDtwP7JnSxwI/TtvHAE+TjbZ5GjinifXZ5h4AVwCn\npe2dgX8HOoBHgf1bdJ+6qte/AkvSPZoHfKRF9bodWA38Jf2MnQN8Gfhyyhdwbar309QY9VZAvS7I\n3a/5wDEtqtdxQABPAYvT59Qy3LOyftx+das+br+6V69Stl911q1t2zDPrG9mZmZWkP78atLMzMys\nUA7EzMzMzAriQMzMzMysIA7EzMzMzAriQMzMzMysIA7EzMzMzAriQMzMzMysIA7EzMzMzAry/wHo\n2rtN9wiu1gAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 720x144 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5O6c5EZlJ3A7",
        "colab_type": "text"
      },
      "source": [
        "Finally, lets try our model on some words we came up with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGIWsq2dElWy",
        "colab_type": "code",
        "outputId": "34183f9e-2f92-4ecf-d0c5-3aa1bf1a8f22",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        }
      },
      "source": [
        "test_words = ['cat', 'floop', 'floegh', 'dog', 'doog', 'dooog', 'tsookdo', 'iwckdj']\n",
        "test_words_x = encode(test_words)\n",
        "test_words_pred_y = discriminator.predict(test_words_x)\n",
        "\n",
        "pd.concat([\n",
        "    pd.DataFrame(test_words, columns=['test_word']),\n",
        "    pd.DataFrame(test_words_pred_y, columns=['score'])], axis=1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>test_word</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>cat</td>\n",
              "      <td>0.732574</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>floop</td>\n",
              "      <td>0.856810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>floegh</td>\n",
              "      <td>0.908125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>dog</td>\n",
              "      <td>0.601068</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>doog</td>\n",
              "      <td>0.655623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>dooog</td>\n",
              "      <td>0.258679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>tsookdo</td>\n",
              "      <td>-0.061626</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>iwckdj</td>\n",
              "      <td>-0.118463</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  test_word     score\n",
              "0       cat  0.732574\n",
              "1     floop  0.856810\n",
              "2    floegh  0.908125\n",
              "3       dog  0.601068\n",
              "4      doog  0.655623\n",
              "5     dooog  0.258679\n",
              "6   tsookdo -0.061626\n",
              "7    iwckdj -0.118463"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3zMk8thKDn_",
        "colab_type": "text"
      },
      "source": [
        "### STEP 6: Let's Generate Fake Words!\n",
        "Let's create another neural network which maps vectors of random numbers to character sequence that get a high score on our model. This is called a GAN and it's frequently used in machine learning to generate real-looking information (think: deep fakes)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "am79T7YNQQTZ",
        "colab_type": "text"
      },
      "source": [
        "A problem we have is that the generator generates tensors that don't match the constraints of our word encoding in that individual letter vectors have numbers rather than a one-hot encoding. Our discriminstator was not trained on this kind of input so it likely won't distinguish words based very accurately. Ideally we want to do do a transformation where only the column with the highest number has a 1 and everything else is 0, but operations like argmax are not differentiable and backpropagation would not work back to the generator.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "We need to understand the Gumbel softmax trick - why.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nxP81XgSKqZR",
        "colab_type": "code",
        "outputId": "ab387a8b-2a94-4f3d-94a8-aacc8f735042",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "latent_dim = 10\n",
        "num_samples = 5000\n",
        "batch_size = 500\n",
        "\n",
        "class GumbalSoftmaxTrick(tf.keras.layers.Layer):\n",
        "  def __init__(self, axis=-1, temperature=0.2, **kwargs):\n",
        "    super(GumbalSoftmaxTrick, self).__init__(**kwargs)\n",
        "    self.supports_masking = True\n",
        "    self.axis = axis\n",
        "    self.temperature = temperature\n",
        "\n",
        "  @staticmethod\n",
        "  def sample_gumbel(shape, eps=1e-20):\n",
        "    U = tf.random.uniform(shape,minval=0,maxval=1)\n",
        "    return -tf.math.log(-tf.math.log(U + eps) + eps)\n",
        "\n",
        "  #def gumbel_softmax_sample(logits, temperature): \n",
        "  #  \"\"\" Draw a sample from the Gumbel-Softmax distribution\"\"\"\n",
        "  #  y = logits + sample_gumbel(tf.shape(logits))\n",
        "  #  return tf.nn.softmax( y / temperature)\n",
        "\n",
        "    #y = gumbel_softmax_sample(logits, temperature)\n",
        "    #if hard:\n",
        "    #  k = tf.shape(logits)[-1]\n",
        "    #  #y_hard = tf.cast(tf.one_hot(tf.argmax(y,1),k), y.dtype)\n",
        "    #  y_hard = tf.cast(tf.equal(y,tf.reduce_max(y,1,keep_dims=True)),y.dtype)\n",
        "    #  y = tf.stop_gradient(y_hard - y) + y\n",
        "    #return y\n",
        "\n",
        "\n",
        "  def call(self, inputs):\n",
        "    #print(inputs)\n",
        "    y = inputs + GumbalSoftmaxTrick.sample_gumbel(tf.shape(inputs))\n",
        "    return tf.keras.backend.softmax(y / self.temperature, axis=self.axis)\n",
        "    #.return tf.keras.backend.softmax(inputs, axis=self.axis)\n",
        "    # return tf.keras.backend.softmax(inputs, axis=self.axis)\n",
        "\n",
        "  def get_config(self):\n",
        "    config = {'axis': self.axis}\n",
        "    config = {'temperature': self.temperature}\n",
        "    base_config = super(GumbalSoftmaxTrick, self).get_config()\n",
        "    return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "  def compute_output_shape(self, input_shape):\n",
        "    return input_shape\n",
        "\n",
        "\n",
        "\n",
        "#print(sample_gumbel(shape=(10,)))\n",
        "\n",
        "# Define a model.\n",
        "# TODO: Consider using BatchNormalisation (BatchNormalization(momentum=0.8))\n",
        "latent_space = tf.keras.layers.Input(shape=(latent_dim,))\n",
        "\n",
        "generator = tf.keras.models.Sequential(name=\"generator\")\n",
        "generator.add(tf.keras.layers.Dense(name='ghidden1', units=500, use_bias=True, activation='tanh', input_dim=latent_dim))\n",
        "generator.add(tf.keras.layers.Dense(name='ghidden2', units=1000, use_bias=True, activation='tanh'))\n",
        "generator.add(tf.keras.layers.Dense(name='ghidden3', units=np.prod(dataset.train.x[0].shape), use_bias=True))\n",
        "generator.add(tf.keras.layers.Reshape(dataset.train.x[0].shape))\n",
        "# TODO: Learn Gumbel Softmax trick, https://blog.evjang.com/2016/11/tutorial-categorical-variational.html\n",
        "generator.add(GumbalSoftmaxTrick(axis=-1, temperature=0.8))\n",
        "\n",
        "#discriminator = tf.keras.models.clone_model(discriminator)\n",
        "#discriminator.set_weights(discriminator.get_weights())\n",
        "discriminator.trainable = False\n",
        "\n",
        "combined = tf.keras.models.Model(latent_space, discriminator(generator(latent_space)))\n",
        "\n",
        "# Compile it.\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
        "combined.compile(loss='binary_crossentropy', optimizer=opt)\n",
        "\n",
        "# Train it.\n",
        "combined_train_x = np.random.normal(0, 1, (num_samples, latent_dim))\n",
        "combined_train_y = np.ones((num_samples, 1))\n",
        "combined_val_x = np.random.normal(0, 1, (num_samples, latent_dim))\n",
        "combined_val_y = np.ones((num_samples, 1))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 10 steps, validate for 10.0 steps\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 1s 142ms/step - loss: 15.4249 - val_loss: 15.4230\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 15.4249 - val_loss: 15.4249\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 15.4222 - val_loss: 15.4249\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 15.4249 - val_loss: 15.4249\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 15.4249 - val_loss: 15.4201\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 15.4249 - val_loss: 15.4249\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 15.4249 - val_loss: 15.4249\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 15.4249 - val_loss: 15.4249\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 15.4223 - val_loss: 15.4249\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 15.4249 - val_loss: 15.4249\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 15.4249 - val_loss: 15.4249\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 15.4249 - val_loss: 15.4194\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 15.4249 - val_loss: 15.4249\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 15.4249 - val_loss: 15.4227\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 15.4249 - val_loss: 15.4249\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 15.4249 - val_loss: 15.4249\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 15.4249 - val_loss: 15.4249\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 15.4249 - val_loss: 15.4229\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 15.4249 - val_loss: 15.4220\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 15.4249 - val_loss: 15.4224\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 15.4249 - val_loss: 15.4249\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 15.4249 - val_loss: 15.4228\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 15.4249 - val_loss: 15.4223\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 15.4196 - val_loss: 15.4249\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 15.4176 - val_loss: 15.4249\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 15.4149 - val_loss: 15.4249\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 15.4192 - val_loss: 15.4229\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 15.4223 - val_loss: 15.4142\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 15.4249 - val_loss: 15.4110\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 15.4134 - val_loss: 15.4098\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 15.4063 - val_loss: 15.4046\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 15.4049 - val_loss: 15.3960\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 15.3005 - val_loss: 15.2168\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 14.8597 - val_loss: 14.2466\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 13.3422 - val_loss: 12.2431\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 11.5590 - val_loss: 10.9273\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 10.6814 - val_loss: 10.1152\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 9.9250 - val_loss: 9.5903\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 9.4686 - val_loss: 9.2557\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 9.2452 - val_loss: 8.9456\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 8.9169 - val_loss: 8.6687\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 8.6762 - val_loss: 8.4886\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 8.4894 - val_loss: 8.2978\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 8.3372 - val_loss: 8.1500\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 42ms/step - loss: 8.1670 - val_loss: 8.0051\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 8.0686 - val_loss: 7.8571\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 7.8964 - val_loss: 7.7803\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 7.7672 - val_loss: 7.6487\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 7.6568 - val_loss: 7.5234\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 7.5754 - val_loss: 7.4652\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 7.4106 - val_loss: 7.2930\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 7.4149 - val_loss: 7.2749\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 7.2081 - val_loss: 7.0575\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 7.0609 - val_loss: 6.8771\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 6.8822 - val_loss: 6.7292\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 6.8371 - val_loss: 6.6836\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 6.7685 - val_loss: 6.6558\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 6.7229 - val_loss: 6.5823\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 6.6627 - val_loss: 6.5467\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 6.5830 - val_loss: 6.5225\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 6.5249 - val_loss: 6.4462\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 6.5039 - val_loss: 6.4089\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 6.4149 - val_loss: 6.3778\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 6.4490 - val_loss: 6.2548\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 6.3571 - val_loss: 6.1739\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 6.2179 - val_loss: 6.1152\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 6.1373 - val_loss: 6.0557\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 6.1015 - val_loss: 6.0440\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 6.0560 - val_loss: 5.9934\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 6.0818 - val_loss: 6.0130\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 6.0736 - val_loss: 5.9951\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 6.0137 - val_loss: 5.9599\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 5.9942 - val_loss: 5.8829\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 5.9704 - val_loss: 5.9022\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 5.9530 - val_loss: 5.8649\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 5.9337 - val_loss: 5.8388\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 5.9327 - val_loss: 5.8578\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 5.8884 - val_loss: 5.7759\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 5.9555 - val_loss: 5.7827\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 5.8220 - val_loss: 5.7594\n",
            "Epoch 81/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 5.7942 - val_loss: 5.7108\n",
            "Epoch 82/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 5.8348 - val_loss: 5.7375\n",
            "Epoch 83/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 5.8008 - val_loss: 5.6917\n",
            "Epoch 84/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 5.7792 - val_loss: 5.6800\n",
            "Epoch 85/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 5.7548 - val_loss: 5.6648\n",
            "Epoch 86/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 5.7143 - val_loss: 5.6747\n",
            "Epoch 87/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 5.7061 - val_loss: 5.6950\n",
            "Epoch 88/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 5.6912 - val_loss: 5.5569\n",
            "Epoch 89/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 5.6298 - val_loss: 5.4501\n",
            "Epoch 90/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 5.4993 - val_loss: 5.4425\n",
            "Epoch 91/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 5.5310 - val_loss: 5.3713\n",
            "Epoch 92/100\n",
            "10/10 [==============================] - 0s 34ms/step - loss: 5.5058 - val_loss: 5.4172\n",
            "Epoch 93/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 5.5060 - val_loss: 5.3845\n",
            "Epoch 94/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 5.4190 - val_loss: 5.3618\n",
            "Epoch 95/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 5.4973 - val_loss: 5.3606\n",
            "Epoch 96/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 5.4596 - val_loss: 5.3362\n",
            "Epoch 97/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 5.4458 - val_loss: 5.3713\n",
            "Epoch 98/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 5.4608 - val_loss: 5.3324\n",
            "Epoch 99/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 5.3813 - val_loss: 5.2897\n",
            "Epoch 100/100\n",
            "10/10 [==============================] - 0s 35ms/step - loss: 5.3985 - val_loss: 5.2297\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7ff670e400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71pahtAnOy_r",
        "colab_type": "code",
        "outputId": "3f5ffdde-4794-443d-f23b-cfcff54d4372",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "generator.layers[4]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<__main__.GumbalSoftmaxTrick at 0x7f7ff677ed30>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A9vJd4rwKx7c",
        "colab_type": "code",
        "outputId": "f643ffb9-ba79-4f02-adfb-0db0b5d79c74",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "combined.fit(to_batched_data_subset(combined_train_x, combined_train_y, batch_size),\n",
        "    validation_data=to_batched_data_subset(combined_val_x, combined_val_y, batch_size), \n",
        "    validation_steps=num_samples/batch_size, verbose=1, epochs=100,\n",
        "    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train for 10 steps, validate for 10.0 steps\n",
            "Epoch 1/100\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0034 - val_loss: 0.0033\n",
            "Epoch 2/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 3.3079e-04 - val_loss: 3.4512e-04\n",
            "Epoch 3/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.0031 - val_loss: 0.0065\n",
            "Epoch 4/100\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0063 - val_loss: 0.0064\n",
            "Epoch 5/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 3.5668e-05 - val_loss: 0.0032\n",
            "Epoch 6/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.0062 - val_loss: 0.0038\n",
            "Epoch 7/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 4.2560e-04 - val_loss: 1.5111e-04\n",
            "Epoch 8/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.0031 - val_loss: 0.0032\n",
            "Epoch 9/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.0033 - val_loss: 6.3468e-04\n",
            "Epoch 10/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.0033 - val_loss: 3.9821e-04\n",
            "Epoch 11/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 3.6892e-05 - val_loss: 0.0033\n",
            "Epoch 12/100\n",
            "10/10 [==============================] - 0s 41ms/step - loss: 0.0063 - val_loss: 2.4480e-04\n",
            "Epoch 13/100\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 0.0034 - val_loss: 8.9621e-05\n",
            "Epoch 14/100\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0069 - val_loss: 0.0031\n",
            "Epoch 15/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 4.6179e-04 - val_loss: 1.0720e-04\n",
            "Epoch 16/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.0031 - val_loss: 0.0063\n",
            "Epoch 17/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.0032 - val_loss: 5.4900e-04\n",
            "Epoch 18/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 4.8798e-05 - val_loss: 0.0035\n",
            "Epoch 19/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.0065 - val_loss: 3.1234e-04\n",
            "Epoch 20/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.0037 - val_loss: 1.6567e-04\n",
            "Epoch 21/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 9.5273e-05 - val_loss: 0.0036\n",
            "Epoch 22/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.0037 - val_loss: 8.5005e-05\n",
            "Epoch 23/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 4.1422e-04 - val_loss: 0.0094\n",
            "Epoch 24/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.0035 - val_loss: 0.0048\n",
            "Epoch 25/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.0032 - val_loss: 0.0063\n",
            "Epoch 26/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 8.3106e-04 - val_loss: 0.0063\n",
            "Epoch 27/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.0031 - val_loss: 0.0037\n",
            "Epoch 28/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 6.5905e-04 - val_loss: 0.0021\n",
            "Epoch 29/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.0043 - val_loss: 0.0033\n",
            "Epoch 30/100\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 1.1898e-04 - val_loss: 3.2581e-05\n",
            "Epoch 31/100\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 1.8756e-04 - val_loss: 1.3578e-04\n",
            "Epoch 32/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 6.3163e-05 - val_loss: 8.5401e-05\n",
            "Epoch 33/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 8.3821e-05 - val_loss: 0.0035\n",
            "Epoch 34/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 1.4980e-04 - val_loss: 2.0476e-04\n",
            "Epoch 35/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 1.5230e-04 - val_loss: 1.2932e-04\n",
            "Epoch 36/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 1.1124e-04 - val_loss: 5.5362e-04\n",
            "Epoch 37/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.0043 - val_loss: 2.2395e-04\n",
            "Epoch 38/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 3.8779e-04 - val_loss: 1.3738e-04\n",
            "Epoch 39/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 3.2985e-05 - val_loss: 8.8060e-05\n",
            "Epoch 40/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 4.6781e-04 - val_loss: 3.4928e-04\n",
            "Epoch 41/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.0033 - val_loss: 7.6850e-04\n",
            "Epoch 42/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 6.2295e-04 - val_loss: 9.3898e-05\n",
            "Epoch 43/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.0034 - val_loss: 4.4202e-05\n",
            "Epoch 44/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 1.0865e-04 - val_loss: 0.0035\n",
            "Epoch 45/100\n",
            "10/10 [==============================] - 0s 40ms/step - loss: 0.0031 - val_loss: 5.0671e-05\n",
            "Epoch 46/100\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 1.9674e-04 - val_loss: 2.2046e-04\n",
            "Epoch 47/100\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 2.5034e-04 - val_loss: 0.0031\n",
            "Epoch 48/100\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 6.1540e-04 - val_loss: 9.0495e-05\n",
            "Epoch 49/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 2.7576e-05 - val_loss: 1.4603e-04\n",
            "Epoch 50/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 4.1417e-04 - val_loss: 2.0659e-04\n",
            "Epoch 51/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 5.8728e-04 - val_loss: 2.6401e-04\n",
            "Epoch 52/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.0034 - val_loss: 2.1345e-04\n",
            "Epoch 53/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 1.4155e-04 - val_loss: 0.0032\n",
            "Epoch 54/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 0.0031 - val_loss: 3.6395e-04\n",
            "Epoch 55/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 3.0059e-04 - val_loss: 3.0151e-04\n",
            "Epoch 56/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 2.8394e-05 - val_loss: 4.2184e-04\n",
            "Epoch 57/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.0032 - val_loss: 9.1698e-04\n",
            "Epoch 58/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 2.2059e-04 - val_loss: 0.0040\n",
            "Epoch 59/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 5.9792e-05 - val_loss: 1.4041e-04\n",
            "Epoch 60/100\n",
            "10/10 [==============================] - 0s 39ms/step - loss: 8.8163e-05 - val_loss: 0.0035\n",
            "Epoch 61/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 5.8800e-04 - val_loss: 4.2571e-04\n",
            "Epoch 62/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 8.7947e-05 - val_loss: 2.0036e-04\n",
            "Epoch 63/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 3.5144e-04 - val_loss: 8.4888e-05\n",
            "Epoch 64/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 0.0031\n",
            "Epoch 65/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 1.9429e-04 - val_loss: 6.1667e-05\n",
            "Epoch 66/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.0031 - val_loss: 5.3444e-04\n",
            "Epoch 67/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 6.1916e-05 - val_loss: 6.7098e-04\n",
            "Epoch 68/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.0032 - val_loss: 0.0033\n",
            "Epoch 69/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 0.0039 - val_loss: 8.1145e-05\n",
            "Epoch 70/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 5.6207e-04 - val_loss: 1.8604e-04\n",
            "Epoch 71/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 4.5470e-04 - val_loss: 0.0032\n",
            "Epoch 72/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 1.8899e-04 - val_loss: 1.1267e-04\n",
            "Epoch 73/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 6.1967e-04 - val_loss: 8.3867e-05\n",
            "Epoch 74/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 1.4200e-04 - val_loss: 3.7839e-04\n",
            "Epoch 75/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 1.0159e-04 - val_loss: 0.0063\n",
            "Epoch 76/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 2.3016e-04 - val_loss: 1.8795e-04\n",
            "Epoch 77/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 2.0881e-04 - val_loss: 2.5129e-04\n",
            "Epoch 78/100\n",
            "10/10 [==============================] - 0s 36ms/step - loss: 9.4130e-05 - val_loss: 2.4948e-04\n",
            "Epoch 79/100\n",
            "10/10 [==============================] - 0s 37ms/step - loss: 0.0031 - val_loss: 0.0032\n",
            "Epoch 80/100\n",
            "10/10 [==============================] - 0s 38ms/step - loss: 9.8349e-05 - val_loss: 0.0032\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f7ff632de10>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3U8O7CNSi2pv",
        "colab_type": "code",
        "outputId": "03bea34f-9e01-43c9-c3c4-1531471142a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "def to_words(prediction):\n",
        "    #print(prediction)\n",
        "    argmax = np.argmax(prediction, axis=-1)\n",
        "    #print(argmax)\n",
        "    as_x = np.zeros(argmax.shape + (27,))\n",
        "    for w in range(argmax.shape[0]):\n",
        "        as_x[w, np.arange(argmax.shape[1]), argmax[w]] = 1\n",
        "    #as_x[np.arange(argmax.shape[0]), np.arange(argmax.shape[1]), argmax] = 1\n",
        "    #print(as_x)\n",
        "    return decode(as_x)\n",
        "\n",
        "generator_out = generator.predict(np.random.normal(0, 1, (20, latent_dim)))\n",
        "blah = to_words(generator_out)\n",
        "#print([len(w) for w in blah])\n",
        "print(blah)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['soerleroororoioieiaee', 'roeoeoroarooelleeieie', 'reoreoreioeoaaeierees', 'iloreroooroolirieiiie', 'reeriirooroollleerlee', 'roereoroorooeeleeieee', 'iooreoreaioroelieoiie', 'roerooroororlaleeroes', 'aoeritrooroolilieiaes', 'aoereeroirootalieilie', 'rueriertoroalloeriaee', 'aeerioroorooerlieiiae', 'roooetroororoeleieiee', 'roureorooroeillieolee', 'reerearoirroleaieieis', 'rooooaroerrleilieeeee', 'teorrorioroooilieolee', 'eooretroorooeeliiieae', 'roerooroorerolleeioee', 'teorreroorerlileeieee']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6iqTcQAP53U",
        "colab_type": "code",
        "outputId": "2a14c1b6-6ba6-494a-8e3f-c312e64ba641",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "generator.predict(np.random.normal(0, 1, (1, latent_dim)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.00651, 0.00374, 0.017, 1.19e-05, 0.00659, 4.57e-07, 8.19e-07, 0.00145, 0.0044, 7.73e-06, 8.56e-06, 0.00107, 2.3e-05, 0.000159, 0.136, 0.0019, 7.13e-08, 0.748, 0.00586, 0.0583, 0.00216, 2.8e-06, 2.89e-08, 3.09e-07, 1.36e-05, 1.64e-05, 0.00733],\n",
              "        [0.011, 5.17e-06, 0.000161, 3.31e-06, 0.0238, 0.000112, 2.3e-05, 0.000395, 0.00612, 5.95e-08, 9.44e-08, 0.00135, 9.25e-06, 0.000633, 0.937, 5.41e-05, 7.61e-09, 0.00658, 0.000489, 0.00282, 0.00679, 4.7e-07, 6.25e-07, 1.78e-08, 1.92e-05, 7.52e-07, 0.0024],\n",
              "        [0.00945, 6.42e-06, 0.0325, 0.00061, 0.407, 7.19e-08, 4.45e-06, 0.000687, 0.0979, 1.55e-05, 1.39e-05, 0.00756, 5.54e-05, 0.0008, 0.406, 0.000103, 3.43e-07, 0.00375, 0.00107, 0.0288, 0.00273, 5.5e-07, 8.28e-07, 6.79e-05, 0.000182, 1.02e-07, 0.000376],\n",
              "        [0.000876, 2e-07, 6.26e-06, 1.65e-05, 0.00113, 3.63e-09, 4.93e-07, 1.95e-05, 0.000337, 2.13e-09, 2.78e-09, 0.000255, 1.78e-06, 0.00011, 0.00839, 9.5e-07, 1.5e-08, 0.987, 0.000273, 0.00105, 0.000323, 9.07e-09, 4.15e-08, 1.38e-09, 1.72e-06, 3.95e-08, 0.000156],\n",
              "        [0.000597, 9.03e-08, 5.61e-06, 2.42e-05, 0.00425, 1.21e-09, 1.65e-07, 0.329, 0.00245, 2.61e-07, 4.47e-06, 0.000151, 1.18e-07, 0.63, 0.0191, 9.18e-08, 5.54e-09, 0.00622, 5.52e-05, 0.00771, 0.000518, 2.12e-07, 2.58e-08, 2.7e-09, 1.13e-05, 3.13e-09, 1.62e-05],\n",
              "        [0.0485, 9.25e-08, 7.35e-05, 1.06e-05, 0.309, 1.16e-06, 6.6e-07, 6.39e-06, 0.00304, 2.36e-08, 4.61e-08, 0.000389, 1.11e-05, 0.000522, 0.147, 9.36e-07, 4.66e-08, 0.0387, 0.00353, 0.446, 0.00207, 1.66e-08, 9e-07, 4.8e-06, 0.000644, 3.67e-07, 0.00101],\n",
              "        [0.00209, 1.06e-05, 0.000106, 1.89e-06, 0.000326, 1.3e-08, 1.83e-08, 0.000503, 0.00097, 1.34e-07, 2.37e-08, 0.00524, 2.14e-06, 0.351, 0.167, 1.21e-07, 2.1e-07, 0.469, 3.66e-05, 0.00249, 0.0016, 1.28e-08, 3.14e-07, 3.17e-09, 2.36e-06, 8.89e-08, 6.44e-05],\n",
              "        [0.0195, 1.5e-05, 2.52e-05, 1.41e-05, 0.204, 7.61e-07, 2.83e-07, 0.00111, 0.00605, 3.3e-07, 1.66e-05, 0.0014, 3.69e-06, 7.09e-05, 0.761, 6.62e-07, 5.11e-07, 0.00454, 0.000836, 0.00128, 2.25e-05, 3.55e-09, 2.24e-07, 2.29e-07, 1.05e-06, 1.36e-07, 5.11e-05],\n",
              "        [0.00492, 5.77e-09, 3.98e-06, 1.78e-06, 0.0391, 7.04e-09, 4.22e-08, 8.13e-07, 0.00168, 1.07e-07, 4.59e-07, 0.00145, 1.24e-06, 0.00051, 0.95, 1.18e-08, 5.43e-08, 9.28e-05, 2.67e-05, 0.00192, 3.44e-05, 5.14e-09, 5.54e-09, 1.29e-09, 7.48e-07, 2.71e-09, 5.87e-06],\n",
              "        [0.0708, 1.15e-07, 2.18e-06, 3.16e-05, 0.00193, 8.4e-07, 1.68e-07, 8.3e-05, 0.0542, 3.06e-06, 3.27e-08, 0.00269, 2.55e-06, 0.000822, 0.0134, 4.39e-05, 5.01e-08, 0.847, 0.000384, 0.00801, 0.000815, 3.76e-07, 8.98e-08, 1.28e-06, 1.07e-05, 1.04e-05, 7.62e-05],\n",
              "        [0.00343, 4.15e-08, 4.41e-06, 2.38e-05, 0.0132, 7.24e-08, 2.02e-07, 1.44e-06, 0.0194, 3.45e-09, 1.52e-08, 3.45e-05, 3.93e-07, 1.99e-06, 0.937, 5.22e-07, 5.83e-08, 0.00214, 1.68e-05, 2.75e-05, 0.0251, 6.79e-09, 4.88e-08, 1.56e-08, 5.45e-05, 8.32e-09, 1.26e-05],\n",
              "        [0.000334, 8.79e-08, 0.000157, 0.000615, 0.0112, 8.2e-08, 6.94e-06, 5.95e-05, 0.0211, 4.64e-06, 7.15e-07, 0.481, 2.56e-06, 0.000659, 0.0213, 1.6e-06, 1.29e-06, 0.0577, 0.00176, 0.402, 0.00132, 3.36e-07, 1.8e-07, 3.39e-07, 8.43e-06, 1.66e-06, 0.000344],\n",
              "        [0.052, 4.01e-08, 4.94e-06, 9.57e-05, 0.0282, 5e-08, 3.75e-07, 0.000192, 0.00709, 9.41e-08, 1.4e-06, 0.161, 0.000153, 1.46e-05, 0.653, 3.25e-08, 1.07e-08, 0.00589, 9.44e-06, 0.00161, 0.000897, 4.94e-07, 6.36e-09, 2.24e-08, 2.24e-05, 3.7e-08, 0.0894],\n",
              "        [0.207, 6.24e-06, 5.9e-06, 0.000362, 0.162, 6.4e-07, 1.41e-06, 3.25e-06, 0.0667, 2.1e-08, 1.4e-08, 0.505, 6.26e-06, 6.01e-05, 0.0106, 6.44e-06, 3.89e-05, 0.034, 0.000226, 0.000161, 0.000549, 3.1e-06, 3.44e-07, 5.69e-08, 0.000131, 7.1e-07, 0.0124],\n",
              "        [0.0103, 8.74e-08, 2.11e-06, 1.47e-05, 0.000773, 9.68e-09, 4.21e-08, 0.000445, 0.00232, 5.11e-08, 1.74e-07, 0.936, 1.22e-07, 1.75e-05, 0.00636, 5.56e-08, 7.35e-09, 0.0139, 8.14e-07, 0.0287, 0.000625, 3.23e-07, 2.78e-09, 1.9e-07, 5.5e-06, 1.17e-08, 0.000337],\n",
              "        [0.00012, 1.45e-09, 1.49e-08, 1.34e-08, 0.00942, 2.94e-10, 6.3e-07, 1.04e-07, 0.984, 7.36e-10, 4.09e-09, 0.000228, 4.51e-08, 1.81e-07, 0.00533, 2.35e-08, 5.88e-08, 0.000494, 0.000613, 7.07e-06, 3.75e-05, 1.39e-10, 1.03e-08, 3.52e-08, 1.38e-07, 3.68e-10, 3.09e-06],\n",
              "        [0.0047, 4.63e-09, 2.2e-07, 2.49e-06, 0.0128, 4.71e-07, 7.83e-07, 1.63e-05, 0.945, 4.54e-08, 6.28e-08, 0.00283, 6.3e-06, 4.83e-05, 0.0313, 6.94e-07, 9.42e-08, 0.00339, 6.92e-06, 4.37e-05, 6.43e-05, 2.36e-07, 8.67e-09, 2.02e-06, 4.99e-06, 3.45e-09, 0.000204],\n",
              "        [0.0259, 1.09e-06, 1.65e-06, 6.33e-07, 0.011, 5.32e-07, 6.77e-07, 3.58e-06, 0.656, 4.88e-05, 1.71e-07, 0.196, 0.000261, 0.000239, 0.0427, 2.8e-06, 3.6e-07, 0.0657, 1.16e-06, 0.000345, 0.000554, 6.32e-07, 1.78e-07, 2.48e-07, 1.81e-05, 1.35e-06, 0.00046],\n",
              "        [0.0292, 2.25e-07, 4.17e-08, 6.99e-09, 0.00134, 6.62e-07, 2.38e-07, 5.85e-09, 0.747, 2.63e-09, 2.36e-10, 0.219, 1.6e-08, 1.05e-05, 0.00208, 2.06e-08, 5.1e-09, 7.39e-05, 4.92e-08, 7.55e-05, 0.000434, 7.06e-07, 8.43e-09, 1.06e-08, 5.25e-05, 6.88e-09, 0.000624],\n",
              "        [0.454, 4.58e-08, 1.03e-06, 5.48e-08, 0.37, 4.32e-09, 3.51e-07, 6.36e-09, 0.00277, 2.24e-07, 1.31e-07, 0.000441, 1.71e-07, 8.48e-05, 0.0562, 8.2e-08, 5.31e-09, 7.21e-05, 1.76e-06, 1.94e-07, 0.117, 1.36e-07, 5.77e-06, 2.03e-08, 1.98e-06, 4.01e-08, 1.7e-06],\n",
              "        [0.00446, 7.48e-12, 5.24e-10, 1.14e-09, 0.877, 2.51e-10, 5.13e-09, 1.31e-06, 4.41e-05, 3.61e-11, 2.7e-10, 8.63e-05, 1.57e-09, 2.79e-06, 5.04e-08, 2.61e-10, 7.65e-10, 8.37e-11, 0.118, 2.16e-07, 2.15e-11, 1.32e-09, 1.98e-10, 3.6e-08, 0.000178, 1.7e-10, 8.07e-11]]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F2zBkRm7ryA9",
        "colab_type": "code",
        "outputId": "eba3ab6b-d6ca-47bf-faa7-fd1effde4091",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import google.colab\n",
        "import os\n",
        "\n",
        "# Work out some directories.\n",
        "gdrive_dir = '/content/gdrive'\n",
        "google.colab.drive.flush_and_unmount()\n",
        "google.colab.drive.mount(gdrive_dir)\n",
        "base_dir = os.path.join(gdrive_dir, 'My Drive', 'Colab Notebooks', 'ml', 'playground', 'english_words', 'english_words_demo')\n",
        "model_filename = os.path.join(base_dir, 'model.h5')\n",
        "\n",
        "# Make sure some directories exist.\n",
        "os.makedirs(base_dir, exist_ok=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-76tpYFmlJN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save(model_filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWr1RMFjkrI1",
        "colab_type": "code",
        "outputId": "a3c83fae-5a14-4b1d-e69c-681b8bfedeb8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls /content/gdrive/My\\ Drive/Colab\\ Notebooks/ml/playground/english_words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "english_words_demo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwKTprR0owWz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.load_model(model_filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McQYNC91daCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l0Buwz_FVrab",
        "colab_type": "text"
      },
      "source": [
        "**Questions**:\n",
        "\n",
        "* To train a model to detect English words we need some training data that isn't English words. What kind of data should we use? How do we get it?\n",
        "* What kind of network is best suited to learn words? What method of turning words into tensors is best suited to ML?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fd53gRrPVyeO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
